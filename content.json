{"pages":[],"posts":[{"title":"01-intro-to-stateful-stream-processing","text":"1. Apache Flink是什么? — Architecture 官网定义： Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale. 其他定义： Apache Flink is a distributed stream processor with intuitive and expressive APIs to implement stateful stream processing applications. It efficiently runs such applications at large scale in a fault-tolerant manner. 2. 传统的数据处理架构传统的数据处理架构一般分为两种类型：transactional processing and analytical processing. transactional processing在传统的关系型事务处理架构下，整个系统被划分为数据处理层（计算层，部署各种应用）和数据存储层（关系型数据库）：在这种架构下，当事件被处理的时候，应用从数据库中读取它的状态或者更新关系型数据库的状态。通常，一个数据库需要同时为多个应用提供服务，那么，当需要扩展关系型数据库或者修改Schema、表名等的时候就要格外小心了。针对这个问题，出现了微服务设计模式，微服务遵循Linux的一次只做一件事儿，且要把这件事儿做好的设计理念，在微服务架构下，各个服务之间是严格解耦合的，应用之间通过接口进行通信，每个服务可以采用不同的技术栈（不同的编程语言，不同的数据存储）来实现。下图展示了一个微服务的一般架构： Analytical Processing和事务型处理应用不同的是，分析型架构一般将数据存储在数据仓库中，这个过程一般是通过ETL工具将数据从日志或者关系型数据库转存到数据仓库。基于数据仓库的查询一般有两类：一类是用来做报表统计，一类是用来做ad-hoc queries（即席查询）。这两类都是基于数据仓库做批次查询。 3. Stateful Stream Processing(有状态数据流处理)有状态数据流处理用来处理那种无界的数据流，先解释一下它是如何执行的：任何处理流式数据且不是来一条就处理一条的应用都需要是stateful的，通过state来保存和获取中间数据。当应用产生一条数据的时候，它可以执行任意从state中读取数据或者将数据写入到state的操作。state可以保存在很多地方：程序变量，本地文本文件，嵌入式的或者外部的数据库等。Apache Flink将状态保存到本地内存或者嵌入式数据库中，由于Flink是一个分布式系统，为了防止机器故障或者应用故障造成本地状态丢失，Flink周期性的将应用state的checkpoint写入到远端的持久化存储中。 有状态流式处理是非常灵活的，也有很多应用场景，下面我们来讨论三个： 4. REAL-WORLD STREAMING USE-CASES4.1 Event-Driven Applications事件驱动应用典型的应用场景包括： 实时推荐（e.g. 消费者浏览购物网站时实时推荐产品） 模式识别和复杂事件处理（e.g. 信用卡交易欺诈检测） 异常检测（e.g. 检测针对计算机网络的攻击尝试） 事件驱动应用是微服务架构的进化，它们通过事件日志而不是Rest接口进行通信。它把应用产生的数据作为本地状态（local state）保存，而不是写入外部存储中。下图是一个典型的事件驱动流式应用的服务架构：上图中应用是通过事件日志进行连接的，前面的应用将输出发送给event log, 后续应用消费event log. 每个应用都可以是stateful的，且都可以本地化存储自己的state而无需访问外部数据库。应用本身也都可以单独扩展。 4.2 Data Pipelines现在的软件架构往往会将一份数据分别放到多种存储中，这种情况下，保持数据的一致性是非常重要的。通常采用ETL定期完成这类工作，但时效性很难保证。因此，可以采用event log来分发更新。所有的更新被写入和分发到event log中，消费端将更新合并到目标存储中。低延迟的摄取、转换、写入数据是有状态流式处理的另一个应用。这类应用被称作data pipeline. Data pipeline必须能在短时间内处理大量的数据。Data pipeline要能够支持不同的数据源和目标源，所有这些，Flink都可以做到。 4.3 Streaming AnalyticsStreaming analytics应用通常用于以下场景： 监控电话网络的质量 分析用户在电话应用中的行为 用户实时数据的即席查询","link":"/2019/09/20/flink/01-intro-to-stateful-stream-processing/"},{"title":"04-the-datastream-api","text":"","link":"/2019/10/06/flink/04-the-datastream-api/"},{"title":"Timeline for Alexis Blog","text":"2018/09/09 First Created.2019/01/01 About Page Added.","link":"/2018/09/09/timeline/timeline/"},{"title":"02-stream-processing-fundamentals","text":"1. 数据流编程简介-Introduction To Dataflow Programming 数据流图-Dataflow Graphs数据流图通常以有向图来表示，有向图的节点（nodes）被称作Operators代表计算，边代表数据依赖。Operators是数据流应用的基本功能单元，Operators从输入源读取数据，进行计算后将结果写入到下一个Opreator。没有输入的Operator叫做输入源（data sources）,没有输出的Operator叫做目标源(data sinks)。 一个数据流图必须至少有一个数据源和一个目标源。下面是一个典型的数据流图。这个图只是一个逻辑图，因为因为它只表达了计算逻辑的高层次抽象。为了执行这个数据流图，逻辑图需要转换成物理流程图。下图是上图对应的物理流程图。在逻辑图中节点代表操作，在物理图中，节点代表任务。 数据交换策略-Data Exchange Strategies下图给出了几种典型的数据交换策略： Forward策略直接将数据从一个任务发送到接收任务。如果两个任务都在同一台物理机上的话，这种策略可以避免跨网络传输 广播策略将一份数据发送到同一个operator的所有并行任务中。这种策略涉及到数据复制和网络传输，因此代价比较大 基于key的策略将数据按照key进行划分，从而保证相同key的数据被相同的任务处理 随机策略将数据随机均匀分配到每个计算任务中 2. Data Stream之上的操作 Data ingestion and data egress这两种操作允许Processor和外部系统打交道。两种操作对应的Operator分别叫做数据源和目标源。 Transformation OperationsTransformation操作一次消费一个事件，将转换操作应用到这个时间数据上，并产生一个新的输出流。 Rolling AggregationsRolling Aggregation是一个聚集操作，例如sum, minimum, maximum, 结果根据每一个事件的到来持续更新。Aggregation操作是有状态的，每次当当前状态和新到来的事件合并到一起，产生一个更新后的聚集结果。 Window OperationsTransformation和Rolling操作一次处理一个事件，产生一个结果事件并更新状态。然而，有些操作必须先buffer一些记录，然后再计算结果。我们给出下面几种窗口： 滚动窗口-Tumbling windows基于数量的滚动窗口给出每次触发计算前需要累积多少数据:基于时间的滚动窗口定义了每次触发计算的时间间隔: 滑动窗口-Sliding windows滑动窗口将事件划分到固定大小的重叠buckets中。因此，一个event可能属于多个buckets。我们通过定义窗口长度和滑动长度（slide）来定义一个滑动窗口。 会话窗口-Session windows考虑一个分析在线用户行为的应用，由于Session的长度不是提前定义的，而是取决于实际数据，因此滚动窗口和滑动窗口都无法应用到这种场景中。因此，我们需要一种能将同一个Session中的数据都放到同一个bucket中window操作。Session Windows操作将事件按照Session进行划分，它会定义一个Session Gap值，这个值表示多长时间不活跃就可以认为一个Session结束了。 并行窗口我们目前看到的window操作都是基于全部的stream数据的。然而现实中，我们可能想把一个Stream划分成多个逻辑Stream，然后定义一个并行窗口。例如你收到了来自于不同场景的应用数据，想把这个数据根据ID进行分组，然后再应用到window操作上： 总结在流式处理中，window操作和两个概念密切相关：时间语义和状态管理(time semantics and state management)。在流式处理中，哪怕我们只是做一个简单的操作，也需要保持状态。考虑一个需要执行很长时间的应用，我们需要确保遇到失败的情况时，状态可以被无误的恢复。因此，下面我们就来探索一下时间语义和失败情况下的状态保证。3. 时间语义-Time Semantics Processing TimeProcessing Time是处理数据的Operator实际执行的时候的本地机器时间。一个processing-time window包含了在一个window周期内到达这个window的所有数据。 Event TimeEvent Time是Stream中一个事件真实发生的时间，Event Time基于一个附属于event之上的时间戳，因此在基于Event-Time的窗口下，及时数据延迟到达，也能被划分到相同的窗口内。 Watermarks到目前为止，我们忽略了一个重要的点，我们何时触发一个时间窗口？我们要等待多长时间才能确定我们已经收到了某一个时间点之前产生的所有数据？我们如何知道数据是否延迟了？接下来，我们看一下如何配置event-time窗口的行为。Watermark是一个全局的程序指标，表示在某一个时间点上，我们确信没有延迟数据会再到达了。本质上，Watermark提供了一个逻辑时钟，通过它来告诉系统当前的事件事件。当一个Operator收到一个带有时间T的watermark时，我们可以知道，不会再收到早于时间T的事件了。当收到watermark时，就会向Operator发出一个信号，告知Operator，某一个时间间隔内的数据都收到了，可以触发计算了。watermark在结果可信度和延迟之间提供了一个权衡。Eager watermark提供低延迟，但可信度低；在这种情况下，有些事件可能在watermark之后到达，我们需要提供代码来处理它们。另一方面，如果watermark设置的较为宽松，那么可信度提高的同时延迟也提高了。需要指出的是，仅仅依赖watermark并不是一个好主意。保证系统提供一些机制来处理那些在watermark之后到来的数据是至关重要的，这些机制可能是忽略它们、记录日志或者使用延迟数据来修正之前的结果。 Processing Time Versus Event Time总结起来，Processing Time提供了低延迟，但是结果依赖于数据处理的速度，不是确定性的，因此常用于实时性比精度要求高的场景或者需要周期性的生成报表而不关心准确性的场景；Event Time确保结果是确定性的，而且可以让我们有机会处理那些迟到的或者乱序的数据。4.状态和一致性模型-State and Consistency ModelStateful operators采用新到来的数据和内部state一起来计算输出。当我们和采用批处理方式处理无界数据集的场景做对比的时候，state就变得更加重要了。在现代流处理系统兴起之前，一个通常的处理无界数据流的方法是周期性的将实时输入的数据划分为小的批次，然后对每一个划分出来的小批次分别做批处理。当一个job完成时，结果被写入到持久化系统中，所有的operator state都会丢失。这个问题的一个通常的解决方式是将state保存到外部系统如数据库中。相反，在持续运行的流式作业中，state是一直持久化到event中的，因此在这类编程模型中，state是一等公民。由于Streaming Operators处理的是无界数据，因此我们要格外小心，别让内部状态无线增长。为了限制state的大小，Operators通常只保存到目前出现的events的一个汇总，可以是count，sum，events的一个sample，一个window buffer，或者保存正在执行的应用的部分属性的自定义数据结构。下面是stateful Operators通常面临的挑战： 状态管理系统需要能高效的管理状态，确保它们不会受到并发更新的影响。 状态分区并行化通常会使事情变得复杂，因为结果既需要依赖状态又需要依赖正在到来的数据。幸运的是，在许多应用场景中，我们可以将状态按照key进行分区，独立地管理它们。 状态恢复stateful Operators面临的最大的挑战是当失败的时候可以确保状态可以被恢复且结果是正确的。5. Result Guarantees At-most-once当任务失败时，最简单的事情是什么都不做，因此不需要从状态恢复数据。或者说，当失败发生时，这期间的事件都会被丢弃，不需要保证结果的正确性。这种保证也可以认为是没有保证，因为哪怕一个系统丢弃所有的数据也可以提供这种级别的保证。没有保证听上去很不到，但如果你只是想要一个近似的结果，并且想要延迟尽可能的低，这不失为一种选择。 At-least-once在大多数应用场景中，我们期望数据不丢失。这种保证被称作最少一次，也就是说所有的events都会被处理，有些events可能会被处理超过1次。当应用的准确性只依赖于信息的完整性时重复处理是可以被接受的。然而，在至少一次的保证下，如果要统计每个事件发生的次数就可能得到错误的结果。 Exactly-onceExactly once是最严格的保证，且很难实现。Exactly-once意味着我们不仅需要保证没有数据丢失，且对每个event的状态更新只会被应用一次。提供Exactly once保证需要At least once保证，因此，data replay机制还是有必要的。此外，Stream Processor需要确保内部状态一致性。在恢复之后，需要只要一个event的更新是否已经被应用到了state上。事务型更新可以实现这个目标，但是可能带来性能问题。相反，Flink采用更轻量级的快照机制来实现Exactly-once的结果保证。 End-to-end Exactly-once我们目前看到的三种状态保证指的是stream processor管理的应用状态。在现实应用中，streaming应用除了一系列的processor外还至少有一个数据源和一个输出源。End-to-end Exactly-once指的是整个数据处理流程的准确性。每个component提供它自己的可靠性保证，那么整个数据流的可靠性保障就是所有组件中最弱的哪一个。有必要指出的是有时候我们可以提供更弱的保证来获取更强的语义。一个例子是当任务做幂等元（如最大和最小）操作的时候，我们可以通过at-least-once保证来实现exactly-once语义。","link":"/2019/09/20/flink/02-stream-processing-fundamentals/"},{"title":"03-the-architecture-of-apache-flink","text":"1.系统架构-System ArchitectureFlink是一个用来做有状态并行数据流处理的分布式系统。一个安装好的Flink包含了分布在多台机器上的多个进程。对于一个分布式系统，需要注意以下要点：集群计算资源分配和管理、进程协调、数据存储的持久化和高可用、错误恢复。Flink并不是自己实现所有这些功能，它关注它的核心功能–分布式数据流处理。Flink和Mesos、Yarn、Kubernates这类集群资源管理应用都集成的很好，Flink也可以以Standalone集群的模式运行。Flink并不提供分布式的持久化存储，而是借助于HDFS和S3这类对象存储。对于高可用模式下的leader选举，Flink借助于Apache Zookeeper来实现。 1.1 Flink组件-Components of a Flink SetupFlink安装后会有下面4个组件：JobManager、ResourceManager、TaskManager、Dispatcher。由于Flink是用Java和Scala来实现的，所有组件都是运行在JVM之上的。这四个组件的职责说明如下： JobManagerJobManager是控制一个application的Master进程，每个application都是被一个不同的JobManager单独控制的。JobManager接收到一个application后开始执行。一个application包含一个JobGraph, 一个逻辑数据流图和一个Jar包。JobManager将JobGraph转化为一个称为ExcutionGraph的物理数据流图，这里面包含了可以并行执行的任务。JobManager向ResourceManager请求执行task所需要的资源（TaskManager slots）。它一获取到足够的TaskManager slots，它就将ExcutionGraph的任务分发到执行它们的TaskManager上。在任务执行的过程中，JobManager负责协调所有任务，如checkpoints。 ResourceManagerFlink为不同的环境和资源提供者（Yarn、Mesos、Kubernates、Standalone）提供了多种ResourceManager。ResourceManager负责管理TaskManager slots（Flink计算资源的基本单元）。当JobManager请求TaskManager slots的时候，ResourceManager就利用空闲的slots为JobManager构建TaskManager。如果ResourceManager没有足够的slot来满足JobManager的请求，ResourceManager就向资源提供者协调来规定TaskManager在哪个container中启动。ResourceManager还负责终止空闲的TaskManager来释放计算资源。 TaskManagerTaskManager是Flink的计算资源。在一个Flink任务中会有多个TaskManager同时运行。每个TaskManager提供固定数量的Slots。slots的数量限制了一个TaskManager可以执行的任务的数量。当TaskManager启动后，它将slots向ResourceManager进行注册。当得到ResourceManager的指示后，TaskManager将一个或多个slots提供给JobManager。这个时候，JobManager就可以将任务分配到slots上来执行。在执行的过程中，一个TaskManager可以和执行同一个应用的其他TaskManager交换数据。 DispatcherDispather在job执行的过程中运行，它提供了一个Rest接口，用来提交application到Flink集群运行。一旦一个application被提交运行，它就启动一个JobManager并将任务交给它。Dispather就像集群的一个入口点，它还提供了一个web界面用来监控作业执行时的基本信息。有的时候，Dispather可能用不到。 注释：这个图中有一个错误，最右侧的ResourceManager实际上应该为TaskManager。 1.2 任务执行–Task Execution一个TaskManager可以同时执行多个task。这个tasks可以是同一个操作的子task（数据并行），不同的操作（任务并行），甚至是不同的应用（作业并行）。TaskManager提供了固定数量的slots来控制它能并发执行的任务数。 1.3 高可用–Highly available setup流式系统一般都是设计为7*24小时无间断运行的。如果发生意外，从失败中恢复一般会经过下面几个步骤：重启失败的进程，重启应用并恢复它的状态。 TaskManager失败TaskManager失败会减少可用的slot数，因此JobManager会向ResourceManager申请提供更多的slot。如果在Standalone模式下，JobManager直到有足够多的可用slot后才会重启应用。 JobManager失败JobManager控制一个流式应用的执行，保存执行过程的元数据（例如指向checkpoint的指针）。如果JobManager消失，流式应用就无法继续执行了，这就导致了JobManager的单点故障。为了解决这个问题，Flink提供了一个高可用模式，在这个模式下，它将一个job的元数据信息同时保存到了另一个JobManager中以防原来的JobManager失败。Flink的高可用也是基于Apache Zookeeper的，Flink采用Zookeeper做leader选举。在高可用模式下，JobManager将JobGraph和所有需要的元数据信息（如应用jar包）写入到一个远程的存储系统中。此外，JobManager将指向存储位置的指针写入到Zookeeper中。因此，所有需要从JobManager失败中恢复所需要的数据都存储在了远端存储系统中，Zookeeper保存了存储位置的指针。当JobManager失败时，所有属于这个应用的task都会被取消。接管它的工作的JobManager会执行如下步骤： 从Zookeeper中请求存储位置来获取JobGraph和Jar文件，从远端存储中获取上次checkpoint的状态信息。 向ResourceManager请求slot继续执行应用 重启应用并重置所有task的状态到上次已经完成的checkpoint位置 2.Flink中的数据流转–Data Transfer in Flink每个TaskManager有一组network buffer（默认为32KB）用来发送和接收数据。如果发送方和接收方跑在不同的TaskManager进程上，那么它们通过操作系统的network stack来交换数据。流式应用需要以Pipeline的形式交换数据–每一对TaskManager之间保持一个永久的TCP连接用来交换数据。在一个Shuffle连接的场景下，每个发送任务都需要给所有的接收任务发送数据，下图是Flink数据流转的基本结构：Flink提供了多种不同的技术来减少任务之间的网络传输开销。下面，我们简单来看一下基于信用的数据流控制（credit-based flow control）和任务链（task chaining）。 credit-based flow control在一个网络连接中只发送单条数据是非常低效率的，此时就需要Buffering来充分利用网络连接的带宽。在流式处理任务中，Buffering的一个缺点是增加了数据消费的延迟。Flink实现了如下的credit-based flow control机制。接收任务向发送任务授予一些credit，即保留接收其数据的网络缓冲区数。发送方收到信用通知后，将发送授予的缓冲区数量及其backlog的大小，即已填充并准备装运的网络缓冲区数。接收方使用保留缓冲区处理已发货的数据，并使用发送方的backlog大小为其所有连接的发送方确定下一次授予credit的优先级。credit-based flow control降低了延迟，因为一旦接收方有资源可以接收数据了，发送方就可以将数据发送给它。更重要的是，它可以应对数据倾斜的有效机制，因为credit的数量是基于发送方backlog的大小来确定的。因此，credit-based flow control是Flink实现高吞吐量和低延迟的一个重要工具。 Task Chaining为了满足Task Chaining的要求，必须至少配置两个operator，它们要有相同的并行度并且以local forward的方式连接。下面的pipeline满足这一要求：下面两张图片分别展示了有TaskChaining的情形和没有TaskChaining的情形：Chained:NonChained:在Flink中TaskChaining是默认开启的。 3.事件时间处理–Event-Time Processing TimeStampsFlink处理的每一条数据都会带有一个timestamp。Flink将timestamp编码为16位的long类型值，并把它们附在记录的metadata中。 Watermarks除了记录的TimeStamp，基于event-time的Flilnk还必须提供Watermarks。基于时间的Operators使用这个时间来进行计算。在Flink中，Timestamp是包含了一个Long类型值的特殊记录。Watermark有两个基本的属性： 它们必须是线性增长的 它们是和记录的TimeStamp相关的，一个包含了T TimeStamp的watermark意味着后续所有记录的TimeStamp都应该大于TWatermark的一个有趣的特点是它允许应用控制结果的准确性和延迟。接近于记录timeStamp的watermark能带来低延迟但结果的完整性可能受到影响因为相关的记录可能还没有被包含进来。相反，保守的watermarks会增加记录延迟但也提高了结果的准确性 Watermark propagation and event time在Flink中，watermark是一条特殊的记录，由Operator tasks接收和发送。Tasks有一个内部的时间服务，当收到一个watermark的时候会被激活。Task可以在timer service注册timer以便在未来的指定时间点进行计算。例如，一个window operator为每一个活跃的window注册一个timer，当事件时间超过窗口结束时间的时候清理掉窗口的状态。当任务收到一个watermark的时候，会执行如下操作： task根据当前watermark的时间戳更新其内部事件时间 task的时间服务找出所有比当前更新后的事件时间小的所有timer。对每一个过期的timer，task调用一个callback函数，该函数可以执行计算并发射记录。 task发送一个带有更新后的时间时间的watermark。下面详细解释一下当一个task收到一个新的watermark的时候怎样向后发送watermark和更新事件时间。我们知道，Flink将数据流划分为多个分区，然后并行处理每个分区。每个分区是一组带有时间戳的记录和watermark数据流。根据Operator怎样和它前后的operator关联，它内部的task可以从一个或多个输入partition接收数据并把数据发送到一个或多个输出partition。下面，我们详细描述一个任务如何把watermark发送给多个输出task，又如何根据从输入task中接收到的watermark更新事件时间时钟的。一个task为每一个输入分区保存一个分区watermark。当它收到一个分区的watermark后，它把当前分区的watermark更新为当前值和收到值的较大值。紧接着，task更新它的事件时间时钟为所有分区watermark的最小值。如果事件时间时钟更新（只会增加），那么task会处理所有触发的时钟并把新的事件时间广播到所有的下游任务。下图展示了一个有四个输入分区、三个输出分区的任务接收watermark、更新内部分区watermark和事件时间时钟，并把新的watermark发送到下游的过程。 Timestamp Assignment and Watermark GenerationFlink数据流应用可以通过以下三种方式分配时间戳和生成水印： At the source：当一个输入流进入到application中时，时间戳和水印可以通过一个SourceFunction生成。记录可以以一个相关的时间戳被一起发送，而水印可以在任意时间点被作为一条特殊的记录发送。 Periodic assigner：DataStream API提供了一个叫做AssignerWithPeriodicWatermarks的用户自定义函数，它从每一条记录中抽取TimeStamp，并可以被当前watermark周期性的查询。 Punctuated assigner: AssignerWithPunctuatedWatermarks是另一种可以从每条记录中抽取TimeStamp的用户自定义函数。通常，用户自定义的TimeStamp分配函数越靠近输入源端越好，因为当记录被Operator处理后就很难判断记录的原始顺序和它们的TimeStamp。 4.状态管理–State Management我们已经知道，大多数流式应用都是有状态的。有众多的Operator持续的读取和更新状态，包括一个window中的记录，输入源的读取位置或者用户自定义的应用级别的Operator状态。Flink将所有State同等对待。下面我们来说明Flink支持的不同类型的state。通常，一个task的所有数据以及一个函数用来计算结果的所有数据都属于这个task的state。我们可以把state看成是一个本地变量或者实例变量，它可以被一个task的业务逻辑访问到。下图展示了task和它的state之间的交互：当Task接收到新的数据后，它可以读取并更新state，同时利用state和获取到的新数据计算结果。一个例子是task持续统计它收到的记录数。当task收到一条新纪录时，它先访问state获取当前的count，再更新count，更新state，最后将新的count发送出去。在Flink中，state总是和一个特定的Operator相关。为了让Flink运行时知道Operator的state，Operator需要注册它的state。有两种类型的state：Operator state和keyed state。 Operator StateOperator state的作用范围是Operator task。这以为这被相同的并行任务处理的记录访问到的都是相同的state。Operator state不能被其他task访问到：Flink为Operator state提供了三种原语（primitives）： List state Union list state Broadcast state Keyed stateKeyed state和定义在输入流中记录中定义的key相关。Flink为每一个key值保存一个state实例，并能将有相同key的记录分到保存有该key的state的Operator上。当task处理一条记录的时候，它自动将state访问的范围变更到当前记录的key上。因此，所有有相同key的记录都访问到相同的state。下图展示了task和keyed state交互的过程：Flink为Keyed state提供了多种原语，下面是其中三种： Value state List state Map state State Backend对处理低延迟数据来说，有效率的state访问是至关重要的，因此每个并行任务会在本地保存状态确保对state的快速访问，在Flink中，由一个叫做state backed的可插拔组件来存储、访问和维护state的准确性。State backed负责两件事情：本地状态管理和将state checkpoint到远端存储。 5.Checkpoints, SavePoints, and State Recovery.Flink作为一个分布式数据处理系统，必须能够处理各种意外情况，如进程被杀掉了，服务器掉线，网络连接中断等异常情况。由于task是在本地管理它们的state的，Flink必须确保在意外情况下这些state不会丢失且还是一致的。 Consistent CheckpointsFlink的恢复机制是基于application state的consistent checkpoints的。一个有状态流应用的consistent checkpoint是在一个点上的所有task的状态拷贝，这时，所有task都处理了完全一致的输入数据。我们来看一个简单的步骤： 暂停消费输入数据 等待所有消费到的数据处理完，即等待所有的task都处理完了它们的输入数据 将每个task 的state复制到远端的持久化存储中，即完成一次Checkpoint 继续所有数据流的消费下图是一个简单应用的consistent checkpoint： Recovery from a consistent checkpoint下图展示了一个恢复过程：应用需要经过以下三步来恢复： 重启整个应用 重置所有有状态task的state到最新的checkpoint。 继续处理所有的任务 Flink’s checkpoint algorithm暂停、checkpoint、恢复这种做法在实际应用中是不可行的，因为在做checkpoint的过程中它停止应用会造成延迟消费。因此，Flink实现了基于Chandy–Lamport算法的checkpoint机制。 SavepointsFlink的恢复算法是基于state的checkpoint的。Checkpoints是根据配置的策略周期性的完成和删除的。Flink的一个重要的且独特的特性是savepoint。savepoint使用和checkpoint同样的算法来创建因此就是比checkpoint多了一些额外的metadata信息。Flink不会自动创建savepoint，必须用户手工触发。Flink也不会自动清理savepoint。从savepoint中启动一个应用一个application包含了多个Operator，每个Operator可以定义一个多多个keyed state或operator state。Operator可以通过一个多多个task并行执行。因此，一个典型的应用包含多个state，它们分布在不同的Operator task中，因此可以分布在不同的TaskManager进程中执行。下图展示了一个有三个Operator的application，每个Operator上跑着两个task。当进行savepoint的时候，所有任务的state被复制到了一个持久化的存储位置中。复制到savepoint中的state是通过一个Operator标识符和和一个state名字来组织的，当应用从savepoint启动时，Flink将savepoint中的数据重新分发到相应Operator的task中。 End","link":"/2019/09/23/flink/03-the-architecture-of-apache-flink/"},{"title":"Java ClassLoader","text":"什么是ClassLoaderJava ClassLoader是一个非常重要但是在平时开发过程中很少直接用到的类，从JDK源码中可以看出ClassLoader是一个抽象类；我们都知道Java程序是跑在JVM上的，当我们编译一个Java类的时候，JVM会将我们写的Java程序转换成以.class作为后缀的字节码程序，这类程序是和平台与机器无关的。当我们尝试使用这个类的时候，ClassLoader就将对应的类加载到内存中。 ClassLoader的类型在Java中，有三种内置的ClassLoader： Bootstrap Class Loader - 负责加载JDK内部的类，即位于$JAVA_HOME/jre/lib目录下的jar包中的类，如rt.jar， charsets.jar等，我们平时常用的java.lang.* 包中的类均是由Bootstrap Class Loader加载的。 Extensions Class Loader - 负责加载$JAVA_HOME/jre/lib/ext目录下的jar包中的类。 System Class Loader - 负责加载当前classpath中的Java类，classpath一般是我们在启动Java程序时通过-cp或者-classpath来指定的 类的加载时机和加载方式（父类委托机制）在以下两种情况下类会被加载： 使用new关键字申请类的实例时，例如：MyClass mc = new MyClass() 代码中使用类的静态引用时，例如：System.out 从上面的图上可以看出，类加载器是采用继承结构的。第一个类是通过我们程序中声明的静态main方法static main()来加载的。下面所有类的加载都是通过已经加载的类来加载的。类加载过程遵循以下原则： 调用findLoadedClass()方法检查要加载的类是否已经被加载了 如果没有被加载，请求它的父类加载器加载请求的类 如果父类加载器无法加载，则尝试自己加载 ClassLoader代码示例：1234567891011121314/** * @author Alexis.Yang * @descriptioin * @date 2019-06-17 20:49 * @copyright www.embracesource.com */public class ClassLoaderExample &#123; public static void main(String[] args) &#123; System.out.println(\"class loader for HashMap: \" + HashMap.class.getClassLoader()); System.out.println(\"class loader for ECPublicKeyImpl\" + sun.security.ec.ECPublicKeyImpl.class.getClassLoader()); System.out.println(\"class loader for this class: \" + ClassLoaderExample.class.getClassLoader()); &#125;&#125; 这段代码的返回结果如下：123class loader for HashMap: nullclass loader for ECPublicKeyImplsun.misc.Launcher$ExtClassLoader@355da254class loader for this class: sun.misc.Launcher$AppClassLoader@18b4aac2 我们可以看出：HashMap的classLoader是null，代表这是由Bootstrap Class Loader来加载的，Bootstrap Class Loader是C++实现的，用Java代码无法获取到，所以得到null；ECPublicKeyImpl是ExtClassLoader加载的，这个类来源于sunec.jar包；而我们的当前类是AppClassLoader或称为System ClassLoader加载的，因为当前类在ClassPath中。 注意父类加载器加载的类对象对子类加载器可见，兄弟类加载器加载的类对象互相不可见。 静态加载VS动态加载 静态类加载通过new关键字完成； 动态类加载通过运行时类型判断，即反射完成； 动态类加载可以通过以下方法完成：getClass(); getName(); getDeclaredFields(); 可以通过调用类名.forName()来获取类的实例；该方法会将类实例加载到当前类的内存中；Java中的静态加载和动态加载 使用new关键字创建对象和实例称为静态类加载。类定义和对象实例化在编译期完成； 使用Class.forName()方法加载类为动态类加载，当在编译器不知道类的名字的时候动态类加载即完成； loadClass和Class.forName的区别loadClass只加载类并不初始化对象实例，而Class.forName在加载类后初始化对象实例。例如，若使用ClassLoader.loadClass加载JDBC驱动的时候，驱动不会被注册，JDBC也无法使用；而java.lang.Class.forName(String className)返回与对象关联的对象实例或者String类型的接口名；如果类找不到则抛出ClassNotFoundException异常。Class.forName的用法如下：123456789101112131415161718192021222324/** * @author Alexis.Yang * @descriptioin * @date 2019-06-17 20:15 * @copyright www.ychenchen.com */public class ClassForNameExample &#123; public static void main(String[] args) &#123; try &#123; Class&lt;?&gt; clazz = Class.forName(\"java.math.BigDecimal\"); System.out.println(\"name = \" + clazz.getName()); System.out.println(\"package = \" + clazz.getPackage()); Constructor&lt;?&gt;[] constructors = clazz.getConstructors(); Field[] declaredFields = clazz.getDeclaredFields(); Method[] declaredMethods = clazz.getDeclaredMethods(); for (Field declaredField: declaredFields) &#123; System.out.println(declaredField.getName()); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 可以看到，通过Class.forName, 类加载了且被实例化了，我们可以获取到类定义的相关信息：1234567891011121314name = java.math.BigDecimalpackage = package java.math, Java Platform API Specification, version 1.8intValscaleprecisionstringCacheINFLATEDINFLATED_BIGINTintCompactMAX_COMPACT_DIGITSserialVersionUIDthreadLocalStringBuilderHelperzeroThroughTen... 参考文档https://www.journaldev.com/349/java-classloader https://javatutorial.net/java-class-loaders-explained https://www.careerride.com/Java-Static-Dynamic-Class.aspx","link":"/2019/06/03/java/jvm/01-classloader/"}],"tags":[{"name":"flink","slug":"flink","link":"/tags/flink/"},{"name":"timeline","slug":"timeline","link":"/tags/timeline/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"}],"categories":[{"name":"flink","slug":"flink","link":"/categories/flink/"},{"name":"timeline","slug":"timeline","link":"/categories/timeline/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"}]}