{"pages":[],"posts":[{"title":"01-intro-to-stateful-stream-processing","text":"1. Apache Flink是什么? — Architecture 官网定义： Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. Flink has been designed to run in all common cluster environments, perform computations at in-memory speed and at any scale. 其他定义： Apache Flink is a distributed stream processor with intuitive and expressive APIs to implement stateful stream processing applications. It efficiently runs such applications at large scale in a fault-tolerant manner. 2. 传统的数据处理架构传统的数据处理架构一般分为两种类型：transactional processing and analytical processing. transactional processing在传统的关系型事务处理架构下，整个系统被划分为数据处理层（计算层，部署各种应用）和数据存储层（关系型数据库）：在这种架构下，当事件被处理的时候，应用从数据库中读取它的状态或者更新关系型数据库的状态。通常，一个数据库需要同时为多个应用提供服务，那么，当需要扩展关系型数据库或者修改Schema、表名等的时候就要格外小心了。针对这个问题，出现了微服务设计模式，微服务遵循Linux的一次只做一件事儿，且要把这件事儿做好的设计理念，在微服务架构下，各个服务之间是严格解耦合的，应用之间通过接口进行通信，每个服务可以采用不同的技术栈（不同的编程语言，不同的数据存储）来实现。下图展示了一个微服务的一般架构： Analytical Processing和事务型处理应用不同的是，分析型架构一般将数据存储在数据仓库中，这个过程一般是通过ETL工具将数据从日志或者关系型数据库转存到数据仓库。基于数据仓库的查询一般有两类：一类是用来做报表统计，一类是用来做ad-hoc queries（即席查询）。这两类都是基于数据仓库做批次查询。 3. Stateful Stream Processing(有状态数据流处理)有状态数据流处理用来处理那种无界的数据流，先解释一下它是如何执行的：任何处理流式数据且不是来一条就处理一条的应用都需要是stateful的，通过state来保存和获取中间数据。当应用产生一条数据的时候，它可以执行任意从state中读取数据或者将数据写入到state的操作。state可以保存在很多地方：程序变量，本地文本文件，嵌入式的或者外部的数据库等。Apache Flink将状态保存到本地内存或者嵌入式数据库中，由于Flink是一个分布式系统，为了防止机器故障或者应用故障造成本地状态丢失，Flink周期性的将应用state的checkpoint写入到远端的持久化存储中。 有状态流式处理是非常灵活的，也有很多应用场景，下面我们来讨论三个： 4. REAL-WORLD STREAMING USE-CASES4.1 Event-Driven Applications事件驱动应用典型的应用场景包括： 实时推荐（e.g. 消费者浏览购物网站时实时推荐产品） 模式识别和复杂事件处理（e.g. 信用卡交易欺诈检测） 异常检测（e.g. 检测针对计算机网络的攻击尝试） 事件驱动应用是微服务架构的进化，它们通过事件日志而不是Rest接口进行通信。它把应用产生的数据作为本地状态（local state）保存，而不是写入外部存储中。下图是一个典型的事件驱动流式应用的服务架构：上图中应用是通过事件日志进行连接的，前面的应用将输出发送给event log, 后续应用消费event log. 每个应用都可以是stateful的，且都可以本地化存储自己的state而无需访问外部数据库。应用本身也都可以单独扩展。 4.2 Data Pipelines现在的软件架构往往会将一份数据分别放到多种存储中，这种情况下，保持数据的一致性是非常重要的。通常采用ETL定期完成这类工作，但时效性很难保证。因此，可以采用event log来分发更新。所有的更新被写入和分发到event log中，消费端将更新合并到目标存储中。低延迟的摄取、转换、写入数据是有状态流式处理的另一个应用。这类应用被称作data pipeline. Data pipeline必须能在短时间内处理大量的数据。Data pipeline要能够支持不同的数据源和目标源，所有这些，Flink都可以做到。 4.3 Streaming AnalyticsStreaming analytics应用通常用于以下场景： 监控电话网络的质量 分析用户在电话应用中的行为 用户实时数据的即席查询","link":"/2019/09/20/flink/01-intro-to-stateful-stream-processing/"},{"title":"03-the-architecture-of-apache-flink","text":"","link":"/2019/09/23/flink/03-the-architecture-of-apache-flink/"},{"title":"Timeline for Alexis Blog","text":"2018/09/09 First Created.2019/01/01 About Page Added.","link":"/2018/09/09/timeline/timeline/"},{"title":"02-stream-processing-fundamentals","text":"1. 数据流编程简介-Introduction To Dataflow Programming 数据流图-Dataflow Graphs数据流图通常以有向图来表示，有向图的节点（nodes）被称作Operators代表计算，边代表数据依赖。Operators是数据流应用的基本功能单元，Operators从输入源读取数据，进行计算后将结果写入到下一个Opreator。没有输入的Operator叫做输入源（data sources）,没有输出的Operator叫做目标源(data sinks)。一个数据流图必须至少有一个数据源和一个目标源。下面是一个典型的数据流图。 这个图只是一个逻辑图，因为因为它只表达了计算逻辑的高层次抽象。为了执行这个数据流图，逻辑图需要转换成物理流程图。下图是上图对应的物理流程图。在逻辑图中节点代表操作，在物理图中，节点代表任务。 数据交换策略-Data Exchange Strategies下图给出了几种典型的数据交换策略： Forward策略直接将数据从一个任务发送到接收任务。如果两个任务都在同一台物理机上的话，这种策略可以避免跨网络传输 广播策略将一份数据发送到同一个operator的所有并行任务中。这种策略涉及到数据复制和网络传输，因此代价比较大 基于key的策略将数据按照key进行划分，从而保证相同key的数据被相同的任务处理 随机策略将数据随机均匀分配到每个计算任务中 2. Data Stream之上的操作 Data ingestion and data egress这两种操作允许Processor和外部系统打交道。两种操作对应的Operator分别叫做数据源和目标源。 Transformation OperationsTransformation操作一次消费一个事件，将转换操作应用到这个时间数据上，并产生一个新的输出流。 Rolling AggregationsRolling Aggregation是一个聚集操作，例如sum, minimum, maximum, 结果根据每一个事件的到来持续更新。Aggregation操作是有状态的，每次当当前状态和新到来的事件合并到一起，产生一个更新后的聚集结果。 Window OperationsTransformation和Rolling操作一次处理一个事件，产生一个结果事件并更新状态。然而，有些操作必须先buffer一些记录，然后再计算结果。我们给出下面几种窗口： 滚动窗口-Tumbling windows 基于数量的滚动窗口给出每次触发计算前需要累积多少数据:基于时间的滚动窗口定义了每次触发计算的时间间隔: 滑动窗口-Sliding windows滑动窗口将事件划分到固定大小的重叠buckets中。因此，一个event可能属于多个buckets。我们通过定义窗口长度和滑动长度（slide）来定义一个滑动窗口。 会话窗口-Session windows考虑一个分析在线用户行为的应用，由于Session的长度不是提前定义的，而是取决于实际数据，因此滚动窗口和滑动窗口都无法应用到这种场景中。因此，我们需要一种能将同一个Session中的数据都放到同一个bucket中window操作。Session Windows操作将事件按照Session进行划分，它会定义一个Session Gap值，这个值表示多长时间不活跃就可以认为一个Session结束了。 并行窗口我们目前看到的window操作都是基于全部的stream数据的。然而现实中，我们可能想把一个Stream划分成多个逻辑Stream，然后定义一个并行窗口。例如你收到了来自于不同场景的应用数据，想把这个数据根据ID进行分组，然后再应用到window操作上： 总结在流式处理中，window操作和两个概念密切相关：时间语义和状态管理(time semantics and state management)。在流式处理中，哪怕我们只是做一个简单的操作，也需要保持状态。考虑一个需要执行很长时间的应用，我们需要确保遇到失败的情况时，状态可以被无误的恢复。因此，下面我们就来探索一下时间语义和失败情况下的状态保证。 3. 时间语义-Time Semantics Processing Time Processing Time是处理数据的Operator实际执行的时候的本地机器时间。一个processing-time window包含了在一个window周期内到达这个window的所有数据。 Event Time Event Time是Stream中一个事件真实发生的时间，Event Time基于一个附属于event之上的时间戳，因此在基于Event-Time的窗口下，及时数据延迟到达，也能被划分到相同的窗口内。 Watermarks 到目前为止，我们忽略了一个重要的点，我们何时触发一个时间窗口？我们要等待多长时间才能确定我们已经收到了某一个时间点之前产生的所有数据？我们如何知道数据是否延迟了？接下来，我们看一下如何配置event-time窗口的行为。Watermark是一个全局的程序指标，表示在某一个时间点上，我们确信没有延迟数据会再到达了。本质上，Watermark提供了一个逻辑时钟，通过它来告诉系统当前的事件事件。当一个Operator收到一个带有时间T的watermark时，我们可以知道，不会再收到早于时间T的事件了。当收到watermark时，就会向Operator发出一个信号，告知Operator，某一个时间间隔内的数据都收到了，可以触发计算了。 watermark在结果可信度和延迟之间提供了一个权衡。Eager watermark提供低延迟，但可信度低；在这种情况下，有些事件可能在watermark之后到达，我们需要提供代码来处理它们。另一方面，如果watermark设置的较为宽松，那么可信度提高的同时延迟也提高了。 需要指出的是，仅仅依赖watermark并不是一个好主意。保证系统提供一些机制来处理那些在watermark之后到来的数据是至关重要的，这些机制可能是忽略它们、记录日志或者使用延迟数据来修正之前的结果。 Processing Time Versus Event Time 总结起来，Processing Time提供了低延迟，但是结果依赖于数据处理的速度，不是确定性的，因此常用于实时性比精度要求高的场景或者需要周期性的生成报表而不关心准确性的场景；Event Time确保结果是确定性的，而且可以让我们有机会处理那些迟到的或者乱序的数据。 4.状态和一致性模型-State and Consistency ModelStateful operators采用新到来的数据和内部state一起来计算输出。当我们和采用批处理方式处理无界数据集的场景做对比的时候，state就变得更加重要了。在现代流处理系统兴起之前，一个通常的处理无界数据流的方法是周期性的将实时输入的数据划分为小的批次，然后对每一个划分出来的小批次分别做批处理。当一个job完成时，结果被写入到持久化系统中，所有的operator state都会丢失。这个问题的一个通常的解决方式是将state保存到外部系统如数据库中。相反，在持续运行的流式作业中，state是一直持久化到event中的，因此在这类编程模型中，state是一等公民。 由于Streaming Operators处理的是无界数据，因此我们要格外小心，别让内部状态无线增长。为了限制state的大小，Operators通常只保存到目前出现的events的一个汇总，可以是count，sum，events的一个sample，一个window buffer，或者保存正在执行的应用的部分属性的自定义数据结构。 下面是stateful Operators通常面临的挑战： 状态管理 系统需要能高效的管理状态，确保它们不会受到并发更新的影响。 状态分区 并行化通常会使事情变得复杂，因为结果既需要依赖状态又需要依赖正在到来的数据。幸运的是，在许多应用场景中，我们可以将状态按照key进行分区，独立地管理它们。 状态恢复 stateful Operators面临的最大的挑战是当失败的时候可以确保状态可以被恢复且结果是正确的。 5. Result Guarantees At-most-once 当任务失败时，最简单的事情是什么都不做，因此不需要从状态恢复数据。或者说，当失败发生时，这期间的事件都会被丢弃，不需要保证结果的正确性。这种保证也可以认为是没有保证，因为哪怕一个系统丢弃所有的数据也可以提供这种级别的保证。没有保证听上去很不到，但如果你只是想要一个近似的结果，并且想要延迟尽可能的低，这不失为一种选择。 At-least-once 在大多数应用场景中，我们期望数据不丢失。这种保证被称作最少一次，也就是说所有的events都会被处理，有些events可能会被处理超过1次。当应用的准确性只依赖于信息的完整性时重复处理是可以被接受的。然而，在至少一次的保证下，如果要统计每个事件发生的次数就可能得到错误的结果。 Exactly-once Exactly once是最严格的保证，且很难实现。Exactly-once意味着我们不仅需要保证没有数据丢失，且对每个event的状态更新只会被应用一次。提供Exactly once保证需要At least once保证，因此，data replay机制还是有必要的。此外，Stream Processor需要确保内部状态一致性。在恢复之后，需要只要一个event的更新是否已经被应用到了state上。事务型更新可以实现这个目标，但是可能带来性能问题。相反，Flink采用更轻量级的快照机制来实现Exactly-once的结果保证。 End-to-end Exactly-once我们目前看到的三种状态保证指的是stream processor管理的应用状态。在现实应用中，streaming应用除了一系列的processor外还至少有一个数据源和一个输出源。End-to-end Exactly-once指的是整个数据处理流程的准确性。每个component提供它自己的可靠性保证，那么整个数据流的可靠性保障就是所有组件中最弱的哪一个。有必要指出的是有时候我们可以提供更弱的保证来获取更强的语义。一个例子是当任务做幂等元（如最大和最小）操作的时候，我们可以通过at-least-once保证来实现exactly-once语义。","link":"/2019/09/20/flink/02-stream-processing-fundamentals/"},{"title":"Java ClassLoader","text":"什么是ClassLoaderJava ClassLoader是一个非常重要但是在平时开发过程中很少直接用到的类，从JDK源码中可以看出ClassLoader是一个抽象类；我们都知道Java程序是跑在JVM上的，当我们编译一个Java类的时候，JVM会将我们写的Java程序转换成以.class作为后缀的字节码程序，这类程序是和平台与机器无关的。当我们尝试使用这个类的时候，ClassLoader就将对应的类加载到内存中。 ClassLoader的类型在Java中，有三种内置的ClassLoader： Bootstrap Class Loader - 负责加载JDK内部的类，即位于$JAVA_HOME/jre/lib目录下的jar包中的类，如rt.jar， charsets.jar等，我们平时常用的java.lang.* 包中的类均是由Bootstrap Class Loader加载的。 Extensions Class Loader - 负责加载$JAVA_HOME/jre/lib/ext目录下的jar包中的类。 System Class Loader - 负责加载当前classpath中的Java类，classpath一般是我们在启动Java程序时通过-cp或者-classpath来指定的 类的加载时机和加载方式（父类委托机制）在以下两种情况下类会被加载： 使用new关键字申请类的实例时，例如：MyClass mc = new MyClass() 代码中使用类的静态引用时，例如：System.out 从上面的图上可以看出，类加载器是采用继承结构的。第一个类是通过我们程序中声明的静态main方法static main()来加载的。下面所有类的加载都是通过已经加载的类来加载的。类加载过程遵循以下原则： 调用findLoadedClass()方法检查要加载的类是否已经被加载了 如果没有被加载，请求它的父类加载器加载请求的类 如果父类加载器无法加载，则尝试自己加载 ClassLoader代码示例：1234567891011121314/** * @author Alexis.Yang * @descriptioin * @date 2019-06-17 20:49 * @copyright www.embracesource.com */public class ClassLoaderExample &#123; public static void main(String[] args) &#123; System.out.println(\"class loader for HashMap: \" + HashMap.class.getClassLoader()); System.out.println(\"class loader for ECPublicKeyImpl\" + sun.security.ec.ECPublicKeyImpl.class.getClassLoader()); System.out.println(\"class loader for this class: \" + ClassLoaderExample.class.getClassLoader()); &#125;&#125; 这段代码的返回结果如下：123class loader for HashMap: nullclass loader for ECPublicKeyImplsun.misc.Launcher$ExtClassLoader@355da254class loader for this class: sun.misc.Launcher$AppClassLoader@18b4aac2 我们可以看出：HashMap的classLoader是null，代表这是由Bootstrap Class Loader来加载的，Bootstrap Class Loader是C++实现的，用Java代码无法获取到，所以得到null；ECPublicKeyImpl是ExtClassLoader加载的，这个类来源于sunec.jar包；而我们的当前类是AppClassLoader或称为System ClassLoader加载的，因为当前类在ClassPath中。 注意父类加载器加载的类对象对子类加载器可见，兄弟类加载器加载的类对象互相不可见。 静态加载VS动态加载 静态类加载通过new关键字完成； 动态类加载通过运行时类型判断，即反射完成； 动态类加载可以通过以下方法完成：getClass(); getName(); getDeclaredFields(); 可以通过调用类名.forName()来获取类的实例；该方法会将类实例加载到当前类的内存中；Java中的静态加载和动态加载 使用new关键字创建对象和实例称为静态类加载。类定义和对象实例化在编译期完成； 使用Class.forName()方法加载类为动态类加载，当在编译器不知道类的名字的时候动态类加载即完成； loadClass和Class.forName的区别loadClass只加载类并不初始化对象实例，而Class.forName在加载类后初始化对象实例。例如，若使用ClassLoader.loadClass加载JDBC驱动的时候，驱动不会被注册，JDBC也无法使用；而java.lang.Class.forName(String className)返回与对象关联的对象实例或者String类型的接口名；如果类找不到则抛出ClassNotFoundException异常。Class.forName的用法如下：123456789101112131415161718192021222324/** * @author Alexis.Yang * @descriptioin * @date 2019-06-17 20:15 * @copyright www.ychenchen.com */public class ClassForNameExample &#123; public static void main(String[] args) &#123; try &#123; Class&lt;?&gt; clazz = Class.forName(\"java.math.BigDecimal\"); System.out.println(\"name = \" + clazz.getName()); System.out.println(\"package = \" + clazz.getPackage()); Constructor&lt;?&gt;[] constructors = clazz.getConstructors(); Field[] declaredFields = clazz.getDeclaredFields(); Method[] declaredMethods = clazz.getDeclaredMethods(); for (Field declaredField: declaredFields) &#123; System.out.println(declaredField.getName()); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 可以看到，通过Class.forName, 类加载了且被实例化了，我们可以获取到类定义的相关信息：1234567891011121314name = java.math.BigDecimalpackage = package java.math, Java Platform API Specification, version 1.8intValscaleprecisionstringCacheINFLATEDINFLATED_BIGINTintCompactMAX_COMPACT_DIGITSserialVersionUIDthreadLocalStringBuilderHelperzeroThroughTen... 参考文档https://www.journaldev.com/349/java-classloader https://javatutorial.net/java-class-loaders-explained https://www.careerride.com/Java-Static-Dynamic-Class.aspx","link":"/2019/06/03/java/jvm/01-classloader/"}],"tags":[{"name":"flink","slug":"flink","link":"/tags/flink/"},{"name":"timeline","slug":"timeline","link":"/tags/timeline/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"}],"categories":[{"name":"flink","slug":"flink","link":"/categories/flink/"},{"name":"timeline","slug":"timeline","link":"/categories/timeline/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"}]}